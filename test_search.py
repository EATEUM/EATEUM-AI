import os
from dotenv import load_dotenv # <--- [í•„ìˆ˜] .env ë¡œë“œ
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

# 1. í™˜ê²½ë³€ìˆ˜(.env) ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")
api_base = os.getenv("OPENAI_API_BASE")

# 2. ìž„ë² ë”© ëª¨ë¸ ì„¤ì • (ingest.pyì™€ 100% ë˜‘ê°™ì•„ì•¼ í•¨!)
# ì¤‘ìš”: ì•„ê¹Œ ingest.pyì—ì„œ 'text-embedding-ada-002'ë¥¼ ì¼ë‹¤ë©´ ì—¬ê¸°ì„œë„ ê·¸ê±¸ ì¨ì•¼ í•©ë‹ˆë‹¤.
embedding_model = OpenAIEmbeddings(
    openai_api_key=api_key,
    openai_api_base=api_base, # GMS ì£¼ì†Œ ì—°ê²°
    model="text-embedding-3-small" # ingest.pyì™€ ë™ì¼í•œ ëª¨ë¸ëª… ìž…ë ¥
)

# 3. ì €ìž¥ëœ DB ë¶ˆëŸ¬ì˜¤ê¸°
db_path = "./chroma_db"

if not os.path.exists(db_path):
    print("âŒ ì—ëŸ¬: 'chroma_db' í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ingest.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!")
    exit()

vectorstore = Chroma(
    persist_directory=db_path, 
    embedding_function=embedding_model # GMS ì„¤ì •ì´ ë‹´ê¸´ ëª¨ë¸ ì£¼ìž…
)

# 4. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
query = "ìžì·¨ìƒì¸ë° ìŠ¤íŒ¸ì´ëž‘ ê³„ëž€ìœ¼ë¡œ í•  ìˆ˜ ìžˆëŠ” ìš”ë¦¬ ìžˆì–´?"
print(f"ðŸ” ì§ˆë¬¸: {query}\n")

print("--- ê²€ìƒ‰ ê²°ê³¼ ---")
# ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ (ìƒìœ„ 3ê°œ)
results = vectorstore.similarity_search(query, k=3)

for i, doc in enumerate(results):
    print(f"[{i+1}ìœ„] {doc.page_content}")
    # CSV ë§Œë“¤ ë•Œ 'id' ì»¬ëŸ¼ì„ ë„£ì—ˆë‹¤ë©´ ì—¬ê¸°ì„œ ë‚˜ì˜µë‹ˆë‹¤.
    recipe_id = doc.metadata.get('id')
    print(f"   ã„´ ID: {recipe_id}") 
    print("-" * 30)

if not results:
    print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (ë°ì´í„°ê°€ ë„ˆë¬´ ì ê±°ë‚˜ ìž„ë² ë”© ëª¨ë¸ì´ ì•ˆ ë§žì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤)")