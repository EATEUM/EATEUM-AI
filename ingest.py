import os
import pandas as pd
from dotenv import load_dotenv
from langchain_community.document_loaders import DataFrameLoader
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.documents import Document

# 1. .env íŒŒì¼ ë¡œë“œ
load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")
api_base = os.getenv("OPENAI_API_BASE")

# ì£¼ì†Œ í™•ì¸ 
print(f"ğŸ”‘ Key Loaded: {api_key[:5]}*****")
print(f"ğŸŒ Base URL: {api_base}")

# 2. ë°ì´í„° ë¡œë“œ ë° ë¬¸ì„œ ë³€í™˜
csv_path = "data/recipes_data.csv" 
df = pd.read_csv(csv_path)

# CSV ì»¬ëŸ¼ í—¤ë”ê°€ ì •í™•í•œì§€ í™•ì¸ (í˜¹ì‹œ ëª¨ë¥¼ ê³µë°± ì œê±°)
df.columns = df.columns.str.strip()

print(f"âœ… CSV íŒŒì¼ ë¡œë“œ ì™„ë£Œ. ì´ {len(df)}ê°œ ë ˆì‹œí”¼.")

docs = []
for index, row in df.iterrows():
    # TODO : ìˆ˜ì •í•  ë¶€ë¶„ 1. ê²€ìƒ‰í•  í…ìŠ¤íŠ¸ ('video_title'ê³¼ 'item_name' í•©ì¹˜ê¸°)
    content = f"ìš”ë¦¬ëª…: {row['video_title']} / ì¬ë£Œ: {row['item_name']}"
    
    # 2. ë©”íƒ€ë°ì´í„° (recipe_video_idë¥¼ IDë¡œ ì €ì¥)
    metadata = {
        "recipe_video_id": row['recipe_video_id'], 
        "video_url": row.get('video_url', ''), 
    }
    
    # LangChain ë¬¸ì„œ ê°ì²´ ìƒì„±
    doc = Document(page_content=content, metadata=metadata)
    docs.append(doc)

print(f"âœ… ì´ {len(docs)}ê°œì˜ ë¬¸ì„œê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ë²¡í„° ë³€í™˜ ì‹œì‘...")

# 3. ì„ë² ë”© ëª¨ë¸ ì„¤ì • (SSAFY GMS ë§ì¶¤ ì„¤ì •)
# ì£¼ì˜: gpt-4.1ì€ ì±„íŒ…ìš© ëª¨ë¸ì…ë‹ˆë‹¤. ì„ë² ë”©ì—ëŠ” ë³´í†µ 'text-embedding-3-small'ì„ ì”ë‹ˆë‹¤.
# ë§Œì•½ ì—ëŸ¬ê°€ ë‚˜ë©´ 'text-embedding-ada-002'ë¡œ ë°”ê¿”ë³´ì„¸ìš”.
embedding_model = OpenAIEmbeddings(
    openai_api_key=api_key,
    openai_api_base=api_base, # GMS ì£¼ì†Œ ì—°ê²°
    model="text-embedding-3-small" # ì„ë² ë”© ì „ìš© ëª¨ë¸
)

# 4. ë²¡í„° DB ìƒì„± ë° ì €ì¥
vectorstore = Chroma.from_documents(
    documents=docs,
    embedding=embedding_model,
    persist_directory="./chroma_db"
)

print("ğŸ‰ ë²¡í„° DB êµ¬ì¶• ì™„ë£Œ! (GMS ì—°ë™ ì„±ê³µ)")